{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae36292c-4e05-42e3-908a-781b055c4bdc",
   "metadata": {},
   "source": [
    "## Campus Devcon - FEU Tech\n",
    "\n",
    "### Sample Implementations of OpenAI Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b83cf8e-24f0-497c-8460-7012553aa773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "import openai\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d2b50-792b-4040-aa90-287fa5adf648",
   "metadata": {},
   "source": [
    "### Load some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a0cb8c-b58a-4829-a786-82846dc3e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(prompt = \"\"):\n",
    "\n",
    "    response = openai.Image.create(\n",
    "      prompt = prompt,\n",
    "      n=1,\n",
    "      size=\"256x256\"\n",
    "    )\n",
    "    \n",
    "    image_url = response['data'][0]['url']\n",
    "\n",
    "    return image_url\n",
    "\n",
    "\n",
    "def generate_image_variation(image_location):\n",
    "\n",
    "    response = openai.Image.create_variation(\n",
    "      image=open(image_location, \"rb\"),\n",
    "      n=1,\n",
    "      size=\"256x256\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']   \n",
    "\n",
    "    return image_url\n",
    "\n",
    "def edit_image(image_location, prompt):\n",
    "\n",
    "    response = openai.Image.create_edit(\n",
    "        image = open(image_location, \"rb\"),\n",
    "        mask = open(\"data/transparent_mask.png\", \"rb\"),\n",
    "        prompt= prompt,\n",
    "        n=1,\n",
    "        size=\"256x256\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    return image_url\n",
    "\n",
    "def load_raw_image(image_location):\n",
    "    return PIL.Image.open(image_location)\n",
    "\n",
    "def save_image(image_url, file_location):\n",
    "    \n",
    "    img_data = requests.get(image_url).content\n",
    "    \n",
    "    with open(file_location, 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "\n",
    "def get_image(image_url):\n",
    "    return Image(url= image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d9670-7c8c-47ed-a6b5-d7f06735ca67",
   "metadata": {},
   "source": [
    "## Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f857ed86-75fa-4833-8872-89dfd8c085f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-KsKJdlgp6fi1a4ecZCTljxxx/user-JeiYAh1LgHL8SnOFhUGQYUew/img-ASEKygjPwkt9ndvsP0KhvZAz.png?st=2023-05-30T21%3A23%3A28Z&se=2023-05-30T23%3A23%3A28Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-05-30T20%3A17%3A29Z&ske=2023-05-31T20%3A17%3A29Z&sks=b&skv=2021-08-06&sig=CPiW6uF0cTTBxuXPzJVuuYqNxNsVGIT8HRsHHWnezAU%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_url = generate_image(prompt = \"playful dog\")\n",
    "get_image(image_url = dog_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c7d7d75-e05c-4531-898a-c2bcdda270ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(image_url = dog_url, file_location = \"data/dog.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201b24c5-02a2-4857-be82-18e3594399a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-KsKJdlgp6fi1a4ecZCTljxxx/user-JeiYAh1LgHL8SnOFhUGQYUew/img-fi49KGTjDGe9FQq4aeRLPbOm.png?st=2023-05-30T21%3A23%3A38Z&se=2023-05-30T23%3A23%3A38Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-05-30T20%3A18%3A04Z&ske=2023-05-31T20%3A18%3A04Z&sks=b&skv=2021-08-06&sig=1bmvM9Ijuh4RT%2BVwi2YV1p/BLun1481UxcIwGLyEmPs%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_dog_url = generate_image_variation(image_location = \"data/dog.png\")\n",
    "get_image(image_url = another_dog_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c16b0b15-2d8a-45b2-8f27-1c2fc55ee59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(image_url = another_dog_url, file_location = \"data/dog1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e98ad5a2-8937-4a3d-81b3-5f146b273464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-KsKJdlgp6fi1a4ecZCTljxxx/user-JeiYAh1LgHL8SnOFhUGQYUew/img-vUDLgAT7mSyQciY3dfU3HjlJ.png?st=2023-05-30T21%3A23%3A46Z&se=2023-05-30T23%3A23%3A46Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-05-30T20%3A17%3A52Z&ske=2023-05-31T20%3A17%3A52Z&sks=b&skv=2021-08-06&sig=NWdllL18dJ8XyMUox5bf7skJOS/ynQZ3Sb%2BNvcYpkbM%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_and_cat_url = generate_image(prompt = \"dog and cat\")\n",
    "get_image(image_url = dog_and_cat_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23d6469-6bb0-4c83-b89b-dc151dc31a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(image_url = dog_and_cat_url, file_location = \"data/cat_and_dog.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4b8d29-036d-4c1e-b0d6-ea57bb1d398b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-KsKJdlgp6fi1a4ecZCTljxxx/user-JeiYAh1LgHL8SnOFhUGQYUew/img-X3cP7VCeIF1kOrlc2yQ8mdI6.png?st=2023-05-30T21%3A24%3A20Z&se=2023-05-30T23%3A24%3A20Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-05-30T20%3A17%3A31Z&ske=2023-05-31T20%3A17%3A31Z&sks=b&skv=2021-08-06&sig=yTbImzJEKjVPwdgbBximCOiHpaskGv7Uu8biJaZnZVI%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_cat_and_dog_url = edit_image(\n",
    "    image_location = \"data/cat_and_dog.png\", \n",
    "    prompt = \"dog and cat are playing in garden\")\n",
    "get_image(image_url = edited_cat_and_dog_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbf9a36e-e931-468e-87e8-52858c88607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(image_url = dog_and_cat_url, file_location = \"data/cat_and_dog_garden.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fc719-c28a-41fb-958d-60c2757d153b",
   "metadata": {},
   "source": [
    "## Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb16c9b7-80fa-4668-a7e1-5c914b3e3a4c",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner. It was not developed for general model deployment - to deploy models like CLIP, researchers will first need to carefully study their capabilities in relation to the specific context they’re being deployed within.\n",
    "\n",
    "The base model uses a ViT-L/14 Transformer architecture as an image encoder and uses a masked self-attention Transformer as a text encoder. These encoders are trained to maximize the similarity of (image, text) pairs via a contrastive loss.\n",
    "\n",
    "The original implementation had two variants: one using a ResNet image encoder and the other using a Vision Transformer. This repository has the variant with the Vision Transformer.\n",
    "\n",
    "See more: https://huggingface.co/openai/clip-vit-large-patch14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "732998aa-1ee2-42c0-8b66-2868931e5ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b423c8268349f392f23f0d8866be60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b20e7b597a2420b9084b99f24d1ed5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6611626a808842e788ea0fe3540ae373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de7a0bde2e849a5addd6c1bcfb3a121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3041c92fdf38409d99d632c777add372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e96f2c11deb416fb9dff8132b10dc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4ad32376d744a2b6a1ec4d02bfe9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288e9b6b84f0431ba4a82d81ad138c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69201be7-28ee-4eb4-abc1-5879113276e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_image = load_raw_image(\"data/dog1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b23562a-2845-4844-a7fb-b1a361072877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(image, labels):\n",
    "\n",
    "    inputs = processor(\n",
    "        text           = labels, \n",
    "        images         = image, \n",
    "        return_tensors = \"pt\", \n",
    "        padding        = True\n",
    "    )\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "    probs = logits_per_image.softmax(dim = 1) \n",
    "    probs = probs.detach().cpu().numpy().tolist()[0]\n",
    "\n",
    "    results = dict(zip(labels,probs))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30566e4c-90e9-4a67-8026-0238e6e091a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a photo of a cat': 0.0020531299524009228,\n",
       " 'a photo of a dog': 0.9979469180107117}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(image = dog_image, labels = [\"a photo of a cat\", \"a photo of a dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94345d76-d0e5-4450-861e-e2e74ac407a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 0.9997114539146423, 'cat': 0.0002885090361814946}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(image = dog_image, labels = [\"dog\", \"cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82f7f7eb-0d52-413a-abe3-6a7b7eea4900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 0.5237144231796265, 'cat': 0.4762856364250183}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catdog_image = load_raw_image(\"data/cat_and_dog.png\")\n",
    "get_prediction(image = catdog_image, labels = [\"dog\", \"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6f12e-1faa-4836-9dd1-f103ab747aec",
   "metadata": {},
   "source": [
    "## Natural language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582f0729-6027-4821-b770-65a7df065999",
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "  {0}\n",
    "  \n",
    "  I never imagined that I would find myself in a situation where I have to explain and defend my decision to leave a marriage, as well as justify the state of my mental health.\n",
    "\n",
    "  It is truly disheartening that I am being questioned and asked to prove my worth as a songwriter and artist. However, despite the overwhelming circumstances, I feel a strong inner calling to stand up for myself and protect my integrity.\n",
    "\n",
    "  I want to set things straight once and for all. Let me be clear: I have never employed a ghostwriter. Throughout my career, I have been fortunate enough to collaborate with immensely talented artists who treat each other with respect and acknowledge the contributions we all bring to the table. \n",
    "\n",
    "  Every song I have created is a true reflection of my deepest emotions and experiences. I am fully prepared to provide evidence that supports this truth, including screenshots of conversations and recordings of my songs, which will undoubtedly validate and disprove the harmful accusations made against me.\n",
    "\n",
    "  I did not cheat on Jason. It is unfair that I find myself in a position where I have to defend my name and even explain why I did not deserve to be cheated on.\n",
    "\n",
    "  Currently, my focus is on the path towards healing, as the weight of trauma still lingers heavily in my heart. This process is not only essential for my own well-being but also for the well-being of those dear to me who have unwaveringly stood by my side throughout these challenging times-my loving family, my dedicated band, my friends, who have all been my source of emotional support.\n",
    "\n",
    "  Their presence has been my anchor, grounding me during these turbulent moments. I hold onto hope that, one day, when the dust settles and clarity is restored, I will have the capacity to embrace a love that is faithful and genuine. I take solace in the knowledge that I am Moira-an artist-who will bravely navigate these challenges and emerge stronger than ever.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d0d4947-c076-4439-9c7d-0baebc28a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis_prompt = statement.format(\"Classify the sentiment of the following statement:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3befdab3-79dd-4ebf-a034-33325b9f2be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe sentiment of this statement is hopeful and determined.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt= sentiment_analysis_prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e16b82d9-30ed-4bc8-b973-a3e494ad68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis_prompt = statement.format(\"Classify as positive or negative sentiment the following statement:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17e8668e-9fff-4cd1-984c-5642baa3b97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis statement is positive sentiment.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt= sentiment_analysis_prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e6f0287-525f-4c16-947a-13471db62aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_prompt = statement.format(\"Summarize the following statement into strictly 2-3 sentences:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef2c7fe6-2c5c-402d-ba6f-f60c0428a585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI am facing difficult circumstances as I have to explain and defend my decision to leave a marriage and justify my mental health. I am determined to stand up for myself and protect my integrity, and I am prepared to provide evidence that I have never employed a ghostwriter. I am focusing on healing and leaning on the support of my loving family, band, and friends. I am hopeful that I will be able to embrace a faithful and genuine love in the future.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt= summarize_prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=120,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7a85d81-8245-4320-9a50-d9abd8b6ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_image_code = \"\"\"\n",
    "    {0}\n",
    "    \n",
    "    def generate_image(prompt = \"\"):\n",
    "    \n",
    "        response = openai.Image.create(\n",
    "          prompt = prompt,\n",
    "          n=1,\n",
    "          size=\"256x256\"\n",
    "        )\n",
    "        \n",
    "        image_url = response['data'][0]['url']\n",
    "    \n",
    "        return image_url\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "842a3275-988c-472a-bcbb-c062c4f6fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = generate_image_code.format(\"Annotate the following code:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9a5726b-cb43-4ee4-8801-624ad79c404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This function takes in an optional prompt string as an argument and uses the OpenAI Image API to generate an image with a size of 256x256. It then returns the URL of the generated image.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt = code_prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=120,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06c3cf31-7080-4d37-97c1-34f0df75983e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n",
      "def generate_image(prompt = \"\"):\n",
      "    \"\"\"\n",
      "    Generates an image based on the given prompt.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    prompt : str\n",
      "        The prompt to generate the image from.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    image_url : str\n",
      "        The URL of the generated image.\n",
      "    \"\"\"\n",
      "    response = openai.Image.create(\n",
      "      prompt = prompt,\n",
      "      n=1,\n",
      "      size=\"256x256\"\n",
      "    )\n",
      "    \n",
      "    image_url = response['data'][0]['url']\n",
      "\n",
      "    return image_url\n"
     ]
    }
   ],
   "source": [
    "code_prompt = generate_image_code.format(\"Update the following code with docstring:\")\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt = code_prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=250,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3604a63-5097-47e8-99bb-b3310a3c9bcd",
   "metadata": {},
   "source": [
    "### Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a430b21-a77e-4ac7-b11c-3a6340110a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(prompt = \"\"):\n",
    "    \"\"\"\n",
    "    Generates an image based on the given prompt.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prompt : str\n",
    "        The prompt to generate the image from.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image_url : str\n",
    "        The URL of the generated image.\n",
    "    \"\"\"\n",
    "    response = openai.Image.create(\n",
    "      prompt = prompt,\n",
    "      n=1,\n",
    "      size=\"256x256\"\n",
    "    )\n",
    "    \n",
    "    image_url = response['data'][0]['url']\n",
    "\n",
    "    return image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff5c092c-921e-484a-a0b6-caa5bcc97383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keywords: Healing, Strength, Support\n",
      "Prompt: Create an image that conveys the power of healing, strength, and support.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-KsKJdlgp6fi1a4ecZCTljxxx/user-JeiYAh1LgHL8SnOFhUGQYUew/img-P7CJsQti2kzt39jo14YZD8ae.png?st=2023-05-30T21%3A37%3A59Z&se=2023-05-30T23%3A37%3A59Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-05-30T20%3A17%3A04Z&ske=2023-05-31T20%3A17%3A04Z&sks=b&skv=2021-08-06&sig=tx0Eiuxy6M%2BqSkCKG/g2LpRljChtLT6FPqO%2B1UDxpkQ%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = statement.format(\"Extract keywords from following statement and create a prompt to create image based on the top 3 derived keywords:\")\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt= prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=120,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "sentiment_prompt = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "print(sentiment_prompt)\n",
    "\n",
    "image_from_sentiment_url = generate_image(prompt = sentiment_prompt)\n",
    "get_image(image_url = image_from_sentiment_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7144c14e-6a82-4bae-af06-6cbc343a6fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3f9a0-12ba-45ea-a15f-35ee239ae666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
